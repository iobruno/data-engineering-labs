## Spark Standalone 4.0
## https://spark.apache.org/docs/4.0.2/spark-standalone.html

## Master-only configs

### Deploy config
spark.deploy.defaultCores=4
spark.deploy.maxExecutorRetries=3

### REST API
spark.master.rest.enabled=true
spark.master.rest.port=6060

### Standalone Cluster Mode only
spark.standalone.submit.waitAppCompletion=false

## Worker-onlly configs

### Shuffling (interval in secs)
spark.worker.cleanup.enabled=true
spark.worker.cleanup.interval=600
spark.shuffle.service.db.enabled=true
spark.shuffle.service.db.backend=ROCKSDB

### Hadoop Configuration for GCS (requires `https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar`)
spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.gs.auth.service.account.enable=true
spark.hadoop.fs.gs.auth.service.account.json.keyfile=/secrets/gcp_credentials.json
