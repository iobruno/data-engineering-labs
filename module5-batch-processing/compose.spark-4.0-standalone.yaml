x-spark-image: &spark-image spark:${SPARK_VERSION:-4.0.1-scala2.13-java21-python3-ubuntu}
x-hive-image:  &hive-image  apache/hive:${HIVE_VERSION:-4.2.0}
x-postgres-image: &postgres-image postgres:${POSTGRES_VERSION:-18.1-alpine}

x-spark-common:
  &spark-common
  image: *spark-image
  environment:
    &spark-common-env
    SPARK_NO_DAEMONIZE: true    # Forces the process to run in foreground (req. for Docker)
  volumes:
    &spark-common-vol
    - vol-spark-extra-jars:/opt/spark/extra-jars/
    - ./spark-4.0-standalone.conf:/opt/spark/conf/spark-standalone.conf
    - ~/.gcp/spark_credentials.json:/secrets/gcp_credentials.json
  depends_on:
    &spark-common-depends-on
    spark-init:
      condition: service_completed_successfully

services:
  spark-master:
    <<: *spark-common
    container_name: spark-master
    command: |
      /opt/spark/sbin/start-master.sh
      --properties-file /opt/spark/conf/spark-standalone.conf
      --webui-port 4040
    ports:
      - '4040:4040'   # default: 8080 for master
      - '7077:7077'
    restart: on-failure:5

  spark-worker1:
    <<: *spark-common
    container_name: spark-worker1
    command: > 
      /opt/spark/sbin/start-worker.sh 
      spark://spark-master:7077 
      --cores 2
      --memory 4G
      --properties-file /opt/spark/conf/spark-standalone.conf
      --webui-port 4041
    ports:
      - '4041:4041'   # default: 8081 for worker
    depends_on:
      spark-master:
        condition: service_started
    restart: on-failure:5

  spark-worker2:
    <<: *spark-common
    container_name: spark-worker2
    command: > 
      /opt/spark/sbin/start-worker.sh 
      spark://spark-master:7077 
      --cores 4
      --memory 6G
      --properties-file /opt/spark/conf/spark-standalone.conf
      --webui-port 4042
    ports:
      - '4042:4042'   # default: 8081 for worker
    depends_on:
      spark-master:
        condition: service_started
    restart: on-failure:5

  spark-connect:
    <<: *spark-common
    container_name: spark-connect
    command: |
      /opt/spark/sbin/start-connect-server.sh
      --master spark://spark-master:7077
      --properties-file /opt/spark/conf/spark-standalone.conf
    ports:
      - '15002:15002'
    depends_on:
      spark-master:
        condition: service_started
    restart: on-failure:3

  hive-db:
    image: *postgres-image
    container_name: hive-metastore-db
    environment:
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: 'postgres'
      POSTGRES_DB: 'metastore'
    ports:
      - '5433:5432'
    volumes:
      - vol-hive-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: on-failure

  hive-metastore:
    image: *hive-image
    container_name: hive-metastore
    environment:
      SERVICE_NAME: 'metastore'
      SERVICE_OPTS: |-
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
        -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://hive-db:5432/metastore
        -Djavax.jdo.option.ConnectionUserName=postgres
        -Djavax.jdo.option.ConnectionPassword=postgres
      HIVE_AUX_JARS_PATH: /opt/hive/aux_jars/
      DB_DRIVER: 'postgres'
    ports:
      - '9083:9083'
    depends_on:
      hive-db:
        condition: service_healthy
      hive-init:
        condition: service_completed_successfully
    volumes:
      - vol-hive-warehouse:/opt/hive/data/warehouse
      - vol-hive-auxjars:/opt/hive/aux_jars/

  spark-init:
    image: *spark-image
    container_name: spark-init
    user: 0:0
    entrypoint: /bin/bash
    command:
      - -c
      - |
        apt-get update && apt-get install curl -y
        curl --create-dirs -O --output-dir /opt/spark/extra-jars/ https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/4.0.2/gcs-connector-4.0.2-shaded.jar
    volumes:
      - vol-spark-extra-jars:/opt/spark/extra-jars/

  hive-init:
    image: *hive-image
    container_name: hive-init
    user: 0:0
    entrypoint: /bin/bash
    command:
      - -c
      - |
        apt update && apt install curl -y
        curl --create-dirs -O --output-dir /tmp/aux_jars https://jdbc.postgresql.org/download/postgresql-42.7.1.jar
    volumes:
      - vol-hive-auxjars:/tmp/aux_jars

volumes:
  vol-spark-extra-jars:
    name: vol-spark-extra-jars
  vol-hive-db:
    name: vol-hive-db
  vol-hive-warehouse:
    name: vol-hive-warehouse
  vol-hive-auxjars:
    name: vol-hive-auxjars
